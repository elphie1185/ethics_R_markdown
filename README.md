# How can we make deep learning more transparent?


## Project Scope
Data ethics project - using R markdown and CSS
This project involved answering the ethical questions: "How can we make deep learning more transparent?" 
The results were presented using R markdown in one of the inbuilt slide presentation format. 
The slides were personalised with CSS.


### Introduction
The first step of the project was to generate a template presentation using R markdown and personalise the slides using CSS. 
The template chosen is shown below: 

![](/screenshots/slide_1.jpg)

### Definitions
I then moved onto explaining what deep learning was using the example of speech recognition. How speech recognition is an exellent concept, particularly useful but how it is far from a perfect technology and how it can fail.

The complexity of deep learning algorithms and neural network was highlighted by comparing the simplicity of a logistic regression against the neural net. 

![](/screenshots/neural_net_rep.jpg)

### Discussion
The talk then moved on to discussing the parts of the process where steps should be included to make deep learning algorithm more transparent. 
Processes such as : 
- INPUT: ensuring that the data collected to train the model is complete and without biases. Making sure that this data is tested against outcome. 
- PROCESS: having a expert in the field of the data to design the analysis and the algorithm process
- OUTPUT: once the algorithm is tained it should be thoroughly tested and validated for reproducibility of the output, any bias of the output

![](/screenshots/Screenshot%202019-09-22%20at%2014.36.43.png)

### Conclusion
Should deep learning algorithm be more transparent? Yes, especially when they are used to make decisions with critical impact on human life. Every step in the process of designing an algorithm should be documented, tested and validated.

![](/screenshots/conclusion.jpg)
